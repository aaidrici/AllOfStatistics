{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alike-tribe",
   "metadata": {},
   "source": [
    "# Chapter 15 Notes\n",
    "\n",
    "# Chapter 15 Exercises\n",
    "\n",
    "### Exercise 15.1\n",
    "\n",
    "\n",
    "1. Proof the first and second statement are equivalent: \n",
    "\n",
    "1.1. independance implies $p_{00}p_{11} = p_{10}p_{01}$\n",
    "$\n",
    "Z \\amalg Y \\implies \\mathbb{P}(Y=y)\\mathbb{P}(Z=z) = \\mathbb{P}(Y=y,Z=z) \\implies \\dfrac{p_{00}p_{11}}{p_{10}p_{01}} =\n",
    "\\dfrac{[\\mathbb{P}(Y=0)\\mathbb{P}(Z=0)][\\mathbb{P}(Y=1)\\mathbb{P}(Z=1)]}{[\\mathbb{P}(Y=1)\\mathbb{P}(Z=0)][\\mathbb{P}(Y=0)\\mathbb{P}(Z=1)]} = 1 \\implies \\psi = 1\n",
    "$\n",
    "\n",
    "1.2.  $p_{00}p_{11} = p_{10}p_{01}$ implies independance: \n",
    "\n",
    "Let $\\mathbb{P}(Z=1, Y=0)=a, \\mathbb{P}(Z=0, Y=0)=b, \\mathbb{P}(Z=1, Y=1)=c$ and $\\mathbb{P}(Z=0, Y=1)=d$ <br> \n",
    "$p_{00}p_{11} = p_{10}p_{01}$ can be re-written $bc = ad$ <br> \n",
    "Also, we can posit from the axioms of probability that $a+b+c+d = 1$, Hence:  <br> \n",
    "$b = b(a+b+c+d) = ba+b^2+bc+db = ba+b^2+ad+db = (b+a)(b+d)$ <br> \n",
    "which can be re-written: <br> \n",
    "$\\mathbb{P}(Z=0, Y=0)= \\mathbb{P}(Y=0)\\mathbb{P}(Z=0)$ <br> \n",
    "The same process can be applied for $a,c$ and $d$, which generalized to the equation:  \n",
    "$\\mathbb{P}(Y=y,Z=z) = \\mathbb{P}(Y=y)\\mathbb{P}(Z=z) \\equiv Z \\amalg Y$ \n",
    "\n",
    "2. Proof the second and third statement are equivalent: \n",
    "\n",
    "$\\lambda = \\log(\\psi) = 0  \\iff e^\\lambda = \\psi = 1$\n",
    "\n",
    "1. Proof the first and fourth statement are equivalent:\n",
    "\n",
    "$\\text{For i,j} \\in \\{0,1\\}, p_{i,j} = p_{\\cdot,j}p_{i,\\cdot}$ <br> \n",
    "$\\equiv \\mathbb{P}(Z=z,Y=y) = \\sum_{i=1}\\mathbb{P}(Y =y_i, Z=z)\\sum_{j=1}\\mathbb{P}(Y=y,Z=z_j) = \\mathbb{P}(Z=z)\\mathbb{P}(Y=y) \\iff Z \\amalg Y $\n",
    "\n",
    "### Exercise 15.2\n",
    "\n",
    "\n",
    "The likelihood ratio statistic: <br> \n",
    "\n",
    "\n",
    "computing the MLE for $H_0$: <br>  \n",
    "$\\mathcal{L}(\\theta)$\n",
    "\n",
    "$f(x;\\theta)  = \\dfrac{n!}{x_{1,1}!x_{1,2}!x_{2,1}!x_{2,2}!}p_{1,1}^{x_{1,1}}p_{1,2}^{x_{1,2}}p_{2,1}^{x_{2,1}}p_{2,2}^{x_{2,2}}$\n",
    "\n",
    "subject to the constraints: <br> \n",
    "(1) $p_{i,j} = p_{\\cdot,j}p_{i,\\cdot}$ <br> \n",
    "(2) $p_{\\cdot,1} + p_{\\cdot,2} = 1$ <br> \n",
    "(3) $p_{1, \\cdot} + p_{2, \\cdot} = 1$ <br> \n",
    "\n",
    "for convience, let re-write: <br> \n",
    "$$p_{\\cdot,1} = \\alpha \\quad p_{\\cdot,2} = 1 - \\alpha \\quad p_{1,\\cdot} = \\beta \\quad p_{2, \\cdot} = 1 - \\beta$$<br> \n",
    "such that $\\theta = [p_{\\cdot,1}, p_{1,\\cdot}] = [\\alpha, \\beta]$\n",
    "\n",
    "$\\dfrac{\\partial^2 f(x;\\theta)}{\\partial\\alpha\\partial\\beta} = \\dfrac{\\partial^2}{\\partial\\alpha\\partial\\beta}\n",
    "\\big(\n",
    "\\dfrac{n!}{x_{1,1}!x_{1,2}!x_{2,1}!x_{2,2}!}(\\alpha\\beta)^{x_{1,1}}((1-\\alpha)\\beta)^{x_{1,2}}(\\alpha(1-\\beta))^{x_{2,1}}((1-\\alpha)(1-\\beta))^{x_{2,2}}\n",
    "\\big)\n",
    "$ <br>\n",
    "$\n",
    " = \\dfrac{\\partial^2}{\\partial\\alpha\\partial\\beta}\n",
    "\\big(\n",
    "\\dfrac{n!}{x_{1,1}!x_{1,2}!x_{2,1}!x_{2,2}!}\n",
    "\\alpha^{x_{1,1}+x_{2,1}}(1-\\alpha)^{x_{1,2}+x_{2,2}}\\beta^{x_{1,1}+x_{1,2}}(1-\\beta)^{x_{2,1}+x_{2,2}}\n",
    "\\big)\n",
    "$ <br> \n",
    "$\n",
    " = \\dfrac{n!}{x_{1,1}!x_{1,2}!x_{2,1}!x_{2,2}!}\n",
    "\\alpha^{x_{1,1}+x_{2,1}-1}(1-\\alpha)^{x_{1,2}+x_{2,2}-1}\n",
    "\\big(\n",
    "-\\alpha(x_{1,2}+x_{2,2}) + (1-\\alpha)(x_{1,1}+x_{2,1})\n",
    "\\big)\n",
    "\\beta^{x_{1,1}+x_{1,2}-1}(1-\\beta)^{x_{2,1}+x_{2,2}-1}\n",
    "\\big(\n",
    "(x_{1,1}+x_{1,2})(1-\\beta) - \\beta((x_{2,1}+x_{2,2}))\n",
    "\\big)\n",
    "$\n",
    "\n",
    "The previous equation can be forced to zero by setting: <br> \n",
    "$$\\alpha = \\dfrac{x_{1,1}+x_{2,1}}{x_{1,1}+x_{2,1} +x_{1,2}+x_{2,2}} = \\dfrac{x_{\\cdot1}}{x_{\\cdot\\cdot}} \\qquad \\beta = \\dfrac{x_{1,1}+x_{1,2}}{x_{1,1}+x_{2,1} +x_{1,2}+x_{2,2}} = \\dfrac{x_{1\\cdot}}{x_{\\cdot\\cdot}}$$\n",
    "\n",
    "Consequently, $\\hat\\theta_0 = [\\dfrac{x_{\\cdot1}x_{1\\cdot}}{x_{\\cdot\\cdot}^2}, \\dfrac{x_{1\\cdot}x_{\\cdot2}}{x_{\\cdot\\cdot}^2}, \\dfrac{x_{\\cdot1}x_{2\\cdot}}{x_{\\cdot\\cdot}^2}, \\dfrac{x_{2\\cdot}x_{\\cdot2}}{x_{\\cdot\\cdot}^2}]$ <br> \n",
    "and $ \\hat\\theta = [x_{11}/x_{\\cdot\\cdot},x_{12}/x_{\\cdot\\cdot},x_{21}/x_{\\cdot\\cdot},x_{22}/x_{\\cdot\\cdot} ]$ \n",
    "\n",
    "$\\lambda = 2\\log\\big(\\dfrac{\\mathcal{L}(\\hat\\theta)}{\\mathcal{L}(\\hat\\theta_0)}\\big)\n",
    " = 2\\log\\big(\\dfrac{(x_{11}/x_{\\cdot\\cdot})^{x_{11}} (x_{12}/x_{\\cdot\\cdot})^{x_{12}}(x_{21}/x_{\\cdot\\cdot})^{x_{21}}(x_{22}/x_{\\cdot\\cdot})^{x_{22}}}\n",
    "{\n",
    "(\\dfrac{x_{\\cdot1}x_{1\\cdot}}{x_{\\cdot\\cdot}^2})^{x_{11}}(\\dfrac{x_{1\\cdot}x_{\\cdot2}}{x_{\\cdot\\cdot}^2})^{x_{12}}\n",
    "(\\dfrac{x_{\\cdot1}x_{2\\cdot}}{x_{\\cdot\\cdot}^2})^{x_{21}}(\\dfrac{x_{2\\cdot}x_{\\cdot2}}{x_{\\cdot\\cdot}^2})^{x_{22}}\n",
    "}\\big)\n",
    "= 2\\log\\big(\n",
    "(\\dfrac{x_{11}x_{\\cdot\\cdot}}{x_{\\cdot1}x_{1\\cdot}})^{x_{11}}(\\dfrac{x_{12}x_{\\cdot\\cdot}}{x_{1\\cdot}x_{\\cdot2}})^{x_{12}}\n",
    "(\\dfrac{x_{21}x_{\\cdot\\cdot}}{x_{\\cdot1}x_{2\\cdot}})^{x_{21}}(\\dfrac{x_{22}x_{\\cdot\\cdot}}{x_{2\\cdot}x_{\\cdot2}})^{x_{22}}\n",
    "\\big)$ <br> \n",
    "$\n",
    " = \\sum_{i=1}^2\\sum_{j=1}^2 2x_{ij}\\log\\big( \\dfrac{x_{ij}x_{\\cdot\\cdot}}{x_{i\\cdot}x_{\\cdot j}}\\big)\n",
    "$\n",
    "and the p-value is $\\mathbb{P}(\\lambda > \\chi_{2,\\alpha})$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Exercise 15.3\n",
    "\n",
    "$p = [p_{11},p_{12},p_{21},p_{22}]$ <br> \n",
    "$\\psi = g(p) = \\frac{p_{11}p_{22}}{p_{12}p_{21}} \\implies \\hat\\psi = g(\\hat p) = \\dfrac{\\hat p_{11}\\hat p_{22}}{\\hat p_{12}\\hat p_{21}} = \\dfrac{(x_{11}/x_{\\cdot\\cdot})(x_{12}/x_{\\cdot\\cdot})}{(x_{21}/x_{\\cdot\\cdot})(x_{22}/x_{\\cdot\\cdot})} = \\dfrac{x_{11}x_{12}}{x_{21}x_{22}}$\n",
    "\n",
    "\n",
    "$\\gamma = \\log(\\psi) \\implies \\hat\\gamma = \\log(\\hat\\psi)$ (equivarience property of MLE) <br> <br>\n",
    "The equivariance properties of the MLE  is assumed to work with one-to-one correspondance function that are smooth, e.g. $g:\\mathbb{R}\\rightarrow\\mathbb{R}$. However, it can be generalized to function that are not necessarily one-to-one, e.g.  $g:\\mathbb{R^n}\\rightarrow\\mathbb{R}$ where $n>1$. See [https://stats.stackexchange.com/questions/77573/invariance-property-of-mle-what-is-the-mle-of-theta2-of-normal-barx2]\n",
    "\n",
    "\n",
    "<b>Part I - standard error of $\\hat\\gamma = h(p)$</b> <br> \n",
    "Let $h(p) = \\log(g(p))$ <br> \n",
    "From the Delta method, we know that <br> \n",
    "$\\sqrt{n}(h(p)-h(\\mu)) \\rightsquigarrow N(0,\\nabla h(p)^T\\Sigma\\nabla h(p))  \\implies $\n",
    "$h(p) \\rightsquigarrow N(h(\\mu),n^{-1}\\nabla h(p)^T\\Sigma\\nabla h(p))$\n",
    "\n",
    "Consequently: <br> \n",
    "$\\hat{se}(\\gamma) = \\hat{se}(h(p)) = \\sqrt{\\mathbb{V}(h(p))} = \\sqrt{n^{-1}\\nabla h(p)^T\\Sigma\\nabla h(p)}$\n",
    "\n",
    "\n",
    "$\\nabla h(p) = [\\dfrac{\\partial\\gamma}{\\partial p_{11}}, \\dfrac{\\partial\\gamma}{\\partial p_{22}}, \\dfrac{\\partial\\gamma}{\\partial p_{12}}, \\dfrac{\\partial\\gamma}{\\partial p_{21}}]\n",
    " = \\dfrac{p_{12}p_{21}}{p_{11}p_{22}}[\\dfrac{p_{22}}{p_{12}p_{21}}, \\dfrac{p_{11}}{p_{12}p_{21}}, \\dfrac{-p_{11}p_{22}}{p_{12}^2p_{21}}, \\dfrac{-p_{11}p_{22}}{p_{12}p_{21}^2}] = \n",
    " [p_{11}^{-1}, p_{22}^{-1}, -p_{12}^{-1}, -p_{21}^{-1}]$ <br>\n",
    "\n",
    "$\\mathbb{V}(p) = \\Sigma = \\begin{bmatrix}\n",
    "(1-p_{11})p_{11} & -p_{11}p_{22} & -p_{11}p_{12} & -p_{11}p_{21}\\\\\n",
    "-p_{22}p_{11} & (1-p_{22})p_{22} &-p_{22}p_{12} & -p_{22}p_{21}\\\\\n",
    "-p_{12}p_{11} & -p_{12}p_{22} & (1-p_{12})p_{12} & -p_{12}p_{21}\\\\\n",
    "-p_{21}p_{11} & -p_{21}p_{22} & -p_{21}p_{12} & (1-p_{21})p_{21}\\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "The content of square root can now be found:  <br> \n",
    "\n",
    "$n^{-1}\\nabla h(p)^T \\Sigma \\nabla h(p) = \n",
    "n^{-1}[ 1, ,1 -,1 -1] \\cdot [p_{11}^{-1}, p_{22}^{-1}, -p_{12}^{-1}, -p_{21}^{-1}]^T = \n",
    "n^{-1}(p_{11}^{-1} + p_{22}^{-1} + p_{12}^{-1} + p_{21}^{-1})$\n",
    "\n",
    "\n",
    "Consequently: <br> \n",
    "$\\hat{se}(\\hat\\gamma) = \\sqrt{n^{-1}\\nabla h(\\hat p)^T \\Sigma \\nabla h(\\hat p) } = \\sqrt{n^{-1}(\\hat p_{11}^{-1} + \\hat p_{22}^{-1} + \\hat p_{12}^{-1} + \\hat p_{21}^{-1})}\n",
    "= \\sqrt{x_{11}^{-1} + x_{22}^{-1} + x_{12}^{-1} + x_{21}^{-1}}$\n",
    "\n",
    "\n",
    "<br><b>Part II - standard error of $\\hat\\psi$</b> <br> \n",
    "$\\nabla g(p) = [\\dfrac{\\partial\\psi}{\\partial p_{11}}, \\dfrac{\\partial\\psi}{\\partial p_{22}}, \\dfrac{\\partial\\psi}{\\partial p_{12}}, \\dfrac{\\partial\\psi}{\\partial p_{21}}]\n",
    " =[\\dfrac{p_{22}}{p_{12}p_{21}},\\dfrac{p_{11}}{p_{12}p_{21}}, \\dfrac{-p_{11}p_{22}}{p_{12}^2p_{21}}, \\dfrac{-p_{11}p_{22}}{p_{12}p_{21}^2} ] = \\dfrac{p_{11}p_{22}}{p_{12}p_{21}}[p_{11}^{-1}, p_{22}^{-1}, -p_{12}^{-1}, -p_{21}^{-1}] = \n",
    " \\psi \\nabla h(p)$ <br>\n",
    "\n",
    "Using the Delta method results in: <br> \n",
    "$\\sqrt{n}(g(p)-g(\\mu)) \\rightsquigarrow N(0,\\nabla g(p)^T\\Sigma\\nabla g(p))  \\implies $\n",
    "$g(p) \\rightsquigarrow N(g(\\mu),n^{-1}\\nabla g(p)^T\\Sigma\\nabla g(p)) = N(g(\\mu),\\psi^2 n^{-1}\\nabla h(p)^T\\Sigma\\nabla h(p))$\n",
    "\n",
    "Consequently: <br> \n",
    "$\\hat{se}(\\hat\\psi) = \\hat{se}(g(\\hat p)) = \\sqrt{\\mathbb{V}(g(\\hat p))} = \\hat\\psi\\sqrt{ n^{-1}\\nabla h(\\hat p)^T\\Sigma\\nabla h(\\hat p)} = \\hat\\psi\\hat{se}(\\hat\\gamma) $ <br> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Exercise 15.4\n",
    "\n",
    "<b>Part I - Discussion on causation</b><br> \n",
    "The likelihood ratio test and Peason $\\chi^2$ test can both be used to reject the null hypothesis that both variable are independant. Additionally, both the odds ration $\\psi$ and log odds ratio $\\gamma$'s CIs suggest both variables are not associated. See part II for results.\n",
    "\n",
    "\n",
    "However, those tools cannot be used to determine if there is <b>causation</b> between both variables. For instance, both variables could be caused by third variable that is <b>geographical location</b>. Region A might be more progressive (death penalty is either banned or difficult for a judge to impose) and its demography has a higher percentage of black indivual, relative to the rest of the country. Northern US states are a good example. Conversely, Region B might be more conservative (death penalty is legal) and has a lower percentage of black individual. \n",
    "    \n",
    "\n",
    "<br>\n",
    "<center><b>Region A</b></center>\n",
    "\n",
    "|  | Death Sentence    | No Death Sentence |\n",
    "|--- |----------| ------|\n",
    "| Black victim | 12 |  90 |\n",
    "| White victim | 61 |  394 |\n",
    "\n",
    "\n",
    "<br>\n",
    "<center><b>Region B</b></center> \n",
    "\n",
    "|  | Death Sentence    | No Death Sentence |\n",
    "|--- |----------| ------|\n",
    "| Black victim | 2  | 551 |\n",
    "| White victim | 1 | 200 |\n",
    "\n",
    "    \n",
    "    \n",
    "<b>Part II - Results of test for association</b> <br> \n",
    "    \n",
    "The odds ratio's 95% confidence interval is $[0.08567, 0.33283]$ when using the first method and $[0.11592, 0.37771]$ when using the second method presented in the both. In both cases, they do not include $1$. This suggests both variables are associated.\n",
    "\n",
    "Also the p-value for the likelihood ratio test and Peason $\\chi^2$ test are respectively equal to 3.17e-08 and 1.068e-07, which also suggest the null hypothesis should be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "variable-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds ratio 95% CL - method 1:\n",
      "[0.08567, 0.33283]\n",
      "\n",
      "Odds ratio 95% CL - method 2:\n",
      "[0.11592, 0.37771]\n",
      "\n",
      "Likelihood ratio test: \n",
      "T = 34.5335\n",
      "chi2_{2,0.95} = 5.9915\n",
      "p-value = 0.0000000317\n",
      "\n",
      "\n",
      "Pearson chi2 test: \n",
      "U = 32.1037\n",
      "chi2_{2,0.95} = 5.9915\n",
      "p-value = 0.0000001068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.stats as st \n",
    "\n",
    "X = np.matrix([[14, 641], [62, 594]])\n",
    "\n",
    "\n",
    "# odds ratio CI \n",
    "psi_hat = 14*594/62/641\n",
    "gamma_hat = np.log(psi_hat)\n",
    "se_gamma_hat = np.sqrt(1/14 + 1/641 + 1/62 + 1/594) \n",
    "se_psi_hat = psi_hat*se_gamma_hat\n",
    "\n",
    "z_a = st.norm.ppf(0.975)\n",
    "\n",
    "print(\"Odds ratio 95% CL - method 1:\")\n",
    "print(f\"[{(psi_hat - z_a*se_psi_hat ):.5f}, {(psi_hat + z_a*se_psi_hat ):.5f}]\\n\")\n",
    "\n",
    "print(\"Odds ratio 95% CL - method 2:\")\n",
    "print(f\"[{np.exp(gamma_hat - z_a*se_gamma_hat):.5f}, {np.exp(gamma_hat + z_a*se_gamma_hat):.5f}]\\n\")\n",
    "\n",
    "# likelihood ratio test \n",
    "T = 0 \n",
    "for i in range(0,2): \n",
    "    for j in range(0,2): \n",
    "        T += X[i,j] * np.log(X[i,j] * np.sum(X[:,:]) / np.sum(X[i,:]) / np.sum(X[:,j]))\n",
    "        \n",
    "T = 2*T\n",
    "print(f\"Likelihood ratio test: \")\n",
    "print(f\"T = {T:.4f}\")\n",
    "print(f\"chi2_{{2,0.95}} = {st.chi2.ppf(0.95, df=2):.4f}\")\n",
    "print(f\"p-value = {1-st.chi2.cdf(T, df=2):.10f}\")\n",
    "\n",
    "# Pearson chi2 test  \n",
    "U = 0 \n",
    "for i in range(0,2): \n",
    "    for j in range(0,2):\n",
    "        E_ij = np.sum(X[i,:]) * np.sum(X[:,j]) / np.sum(X[:,:])\n",
    "        U += np.power((X[i,j] - E_ij),2) / E_ij \n",
    "\n",
    "print(f\"\\n\\nPearson chi2 test: \")\n",
    "print(f\"U = {U:.4f}\")\n",
    "print(f\"chi2_{{2,0.95}} = {st.chi2.ppf(0.95, df=2):.4f}\")\n",
    "print(f\"p-value = {1-st.chi2.cdf(U, df=2):.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-reception",
   "metadata": {},
   "source": [
    "### Exercise 15.5\n",
    "\n",
    "The likelihood ratio test and Peason $\\chi^2$ test can both be used to reject the null hypothesis that both variable are independant. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "timely-terrace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood ratio test: \n",
      "T = 22.0637\n",
      "chi2_{2,0.95} = 9.4877\n",
      "p-value = 0.0001946516\n",
      "\n",
      "\n",
      "Pearson chi2 test: \n",
      "U = 20.6793\n",
      "chi2_{2,0.95} = 9.4877\n",
      "p-value = 0.0003665590\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.stats as st\n",
    "url  = \"http://www.stat.cmu.edu/~larry/all-of-statistics/=data/montana.dat\"\n",
    "\n",
    "file = urllib.request.urlopen(url)\n",
    "\n",
    "# load all data into a single table \n",
    "names = ['AGE','SEX','INC','POL','AREA','FIN','STAT']\n",
    "dim = ['AGE','SEX','INC','POL','AREA','FIN','STAT']\n",
    "X_comp = [] \n",
    "lines = []\n",
    "line_count = 0 \n",
    "for line in file:\n",
    "    line_count += 1\n",
    "    if (line_count >= 34):  \n",
    "        full_line = line.decode(\"utf-8\").split() \n",
    "        X_comp.append(full_line) \n",
    "        \n",
    "X_comp = np.matrix(X_comp)     \n",
    "X_comp = np.concatenate(X_comp, axis=0)\n",
    "\n",
    "x_age = X_comp[:,0]\n",
    "x_fin = X_comp[:,5]\n",
    "\n",
    "# construct table for age vs financial status \n",
    "table = np.zeros([3,3], dtype = float)\n",
    "for i in range(0,len(x_age)):\n",
    "    if (x_fin[i] == '*' or x_age[i] == '*'): \n",
    "        continue\n",
    "    k = int(x_age[i])-1\n",
    "    p = int(x_fin[i])-1\n",
    "    table[k,p] +=1\n",
    "\n",
    "# apply chi square test \n",
    "T = 0 \n",
    "for i in range(0,3): \n",
    "    for j in range(0,3): \n",
    "          T += table[i,j] * np.log(table[i,j]*np.sum(table[:,:]) / np.sum(table[i,:]) / np.sum(table[:,j]))\n",
    "T *= 2\n",
    "\n",
    "dof = (table.shape[0]-1)*(table.shape[1]-1)\n",
    "\n",
    "print(f\"Likelihood ratio test: \")\n",
    "print(f\"T = {T:.4f}\")\n",
    "print(f\"chi2_{{2,0.95}} = {st.chi2.ppf(0.95, df=dof):.4f}\")\n",
    "print(f\"p-value = {1-st.chi2.cdf(T, df=dof):.10f}\")\n",
    "\n",
    "# Pearson chi2 test  \n",
    "U = 0 \n",
    "for i in range(0,3): \n",
    "    for j in range(0,3):\n",
    "        E_ij = np.sum(table[i,:]) * np.sum(table[:,j]) / np.sum(table[:,:])\n",
    "        U += np.power((table[i,j] - E_ij),2) / E_ij \n",
    "\n",
    "print(f\"\\n\\nPearson chi2 test: \")\n",
    "print(f\"U = {U:.4f}\")\n",
    "print(f\"chi2_{{2,0.95}} = {st.chi2.ppf(0.95, df=dof):.4f}\")\n",
    "print(f\"p-value = {1-st.chi2.cdf(U, df=dof):.10f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-location",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 15.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "handy-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated rho: -0.6481\n",
      "95% confidence interval (Fisher method):\n",
      "[-0.7608, -0.4976]\n",
      "95% confidence interval (Bootstrap method):\n",
      "[-0.6204, -0.7029]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import urllib, pandas \n",
    "import scipy.stats as st \n",
    "url  = \"http://www.stat.cmu.edu/~larry/all-of-statistics/=data/temp.dat\"\n",
    "\n",
    "file = urllib.request.urlopen(url)\n",
    "\n",
    "\n",
    "X = [] \n",
    "city_list = []\n",
    "    \n",
    "\n",
    "line_count = 0 \n",
    "for line in file:\n",
    "    line_count += 1\n",
    "    if (line_count >= 33):  \n",
    "        full_line = line.decode(\"utf-8\").split() \n",
    "        \n",
    "        n = len(full_line)\n",
    "        city_name = ''.join(full_line[0:n-3])\n",
    "        otherCovariates = full_line[-3:]\n",
    "        for j in range(0,len(otherCovariates)): # convert strings to float \n",
    "            otherCovariates[j] = float(otherCovariates[j])\n",
    "        X.append(otherCovariates)\n",
    "        city_list.append(city_name)\n",
    "        \n",
    "X = np.matrix(X)     \n",
    "X = np.concatenate(X, axis=0)\n",
    "\n",
    "temp = X[:,0]\n",
    "lat = X[:,1]\n",
    "temp = np.squeeze(np.asarray(temp))\n",
    "lat = np.squeeze(np.asarray(lat))\n",
    "\n",
    "n = len(lat)\n",
    "\n",
    "def rho_est(lat, temp):\n",
    "    s_lat = 1/(n-1) * np.sum(np.power(lat - np.mean(lat), 2))\n",
    "    s_temp = 1/(n-1) * np.sum(np.power(temp - np.mean(temp), 2))\n",
    "    rho_hat = np.sum(np.multiply(lat-np.mean(lat),temp-np.mean(temp))) / s_lat / s_temp\n",
    "    return rho_hat\n",
    "\n",
    "rho_hat = rho_est(lat,temp)\n",
    "print(f\"Estimated rho: {rho_hat:.4f}\")\n",
    "\n",
    "\n",
    "# CI using the Fisher method: \n",
    "theta_hat = 1/2 * (np.log(1+rho_hat) - np.log(1-rho_hat))\n",
    "z_a = st.norm.ppf(0.95)\n",
    "a,b = theta_hat - z_a/np.sqrt(n-3),  theta_hat + z_a/np.sqrt(n-3)\n",
    "lb, rb = (np.exp(2*a)-1)/(np.exp(2*a)+1), (np.exp(2*b)-1)/(np.exp(2*b)+1)\n",
    "\n",
    "print(f\"95% confidence interval (Fisher method):\")\n",
    "print(f\"[{lb:.4f}, {rb:.4f}]\")\n",
    "\n",
    "\n",
    "# CI using bootstrap method \n",
    "subsample_size = n\n",
    "trial_number = 1000\n",
    "rho_list = [None]*trial_number\n",
    "for i in range(0,trial_number):\n",
    "    id_rand = np.random.randint(0,n, size = subsample_size)\n",
    "    rho_list[i] = rho_est(lat[id_rand], temp[id_rand])\n",
    "np.sort(rho_list)\n",
    "lb_btstrp = rho_list[int(trial_number*0.025)]\n",
    "rb_btstrp = rho_list[int(trial_number*0.975)]\n",
    "\n",
    "print(f\"95% confidence interval (Bootstrap method):\")\n",
    "print(f\"[{lb_btstrp:.4f}, {rb_btstrp:.4f}]\")  \n",
    "\n",
    "plt.show()\n",
    "plt.figure(1)\n",
    "plt.plot(lat,temp,'.')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Test null hypotheses that rho_hat = 0 using log likelihood ratio\n",
    "\n",
    "# MLE theta_0\n",
    "sig_11 = 1/(n-1) * np.sum(np.power(lat - np.mean(lat), 2))\n",
    "sig_22 = 1/(n-1) * np.sum(np.power(temp - np.mean(temp), 2))\n",
    "Sigma_inv = np.matrix([[1/sig_11,0],[0,1/sig_22]])\n",
    "Sigma_det = sig_11 * sig_22\n",
    "# MLE theta\n",
    "sig_12 = 1/(n-1) *np.sum(np.multiply(lat-np.mean(lat),temp-np.mean(temp)))\n",
    "Sigma__det = sig_11 * sig_22 - sig_12*sig_12\n",
    "Sigma__inv = np.linalg.inv(np.matrix([[sig_11, s_12],[s_12, s_22]]))\n",
    "\n",
    "mu = np.matrix([np.mean(lat), np.mean(temp)])\n",
    "\n",
    "log_like0 = 0 \n",
    "log_like = 0 \n",
    "for i in range(0,n):\n",
    "    x = np.matrix([lat[i], temp[i]])\n",
    "\n",
    "    # Compute loglikelihood when constrained to rho = 0 \n",
    "    log_like0 += 1 / (2*3.1415*np.sqrt(Sigma_det)) *np.exp(-1/2 * (x-mu).dot(Sigma_inv).dot((x-mu).transpose()))\n",
    "    # Compute loglikelihood when constrained to rho = 0 \n",
    "    log_like += 1 / (2*3.1415*np.sqrt(Sigma__det)) *np.exp(-1/2 * (x-mu).dot(Sigma_inv).dot((x-mu).transpose()))\n",
    "\n",
    "\n",
    "#http://www.stat.cmu.edu/~larry/all-of-statistics/=data/temp.dat\n",
    "#http://www.stat.cmu.edu/~larry/all-of-statistics/=data/calcium.dat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-queue",
   "metadata": {},
   "source": [
    "### Exercise 15.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-credits",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
